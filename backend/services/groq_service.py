"""
Groq Service
‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Groq LLM API
"""

import os
from typing import List, Dict, Optional
from groq import Groq
from dotenv import load_dotenv

# Load environment variables
load_dotenv()


class GroqService:
    """Service ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Groq LLM"""
    
    def __init__(self):
        """Initialize Groq client"""
        api_key = os.getenv("GROQ_API_KEY")
        if not api_key:
            raise ValueError("GROQ_API_KEY not found in environment variables")
        
        self.client = Groq(api_key=api_key)
        self.model = os.getenv("MODEL_NAME", "llama-3.3-70b-versatile")
        
        # Default parameters
        self.temperature = 0.7  # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏£‡∏Ñ‡πå (0-2)
        self.max_tokens = 1024  # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á response
        self.top_p = 0.9        # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö
    
    async def generate_response(
        self,
        system_prompt: str,
        user_message: str,
        conversation_history: Optional[List[Dict[str, str]]] = None,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None
    ) -> str:
        """
        ‡∏™‡∏£‡πâ‡∏≤‡∏á response ‡∏à‡∏≤‡∏Å LLM
        
        Args:
            system_prompt: System prompt (‡∏ö‡∏∏‡∏Ñ‡∏•‡∏¥‡∏Å‡πÅ‡∏•‡∏∞‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏Ç‡∏≠‡∏á bot)
            user_message: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤
            conversation_history: ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤ (Optional)
            temperature: ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏£‡∏Ñ‡πå (Optional)
            max_tokens: ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î (Optional)
            
        Returns:
            response text ‡∏à‡∏≤‡∏Å LLM
        """
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á messages array
        messages = [
            {"role": "system", "content": system_prompt}
        ]
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏° conversation history ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
        if conversation_history:
            messages.extend(conversation_history)
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å user
        messages.append({"role": "user", "content": user_message})
        
        # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å Groq API
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=temperature or self.temperature,
                max_tokens=max_tokens or self.max_tokens,
                top_p=self.top_p,
                stream=False
            )
            
            # ‡∏î‡∏∂‡∏á response text
            return response.choices[0].message.content
            
        except Exception as e:
            print(f"‚ùå Groq API Error: {e}")
            return self._get_fallback_response(user_message)
    
    async def generate_response_with_extraction(
        self,
        system_prompt: str,
        user_message: str,
        conversation_history: Optional[List[Dict[str, str]]] = None,
        extraction_schema: Optional[Dict] = None
    ) -> Dict:
        """
        ‡∏™‡∏£‡πâ‡∏≤‡∏á response ‡πÅ‡∏•‡∏∞ extract structured data
        
        Args:
            system_prompt: System prompt
            user_message: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å user
            conversation_history: ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤
            extraction_schema: Schema ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö extract ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
            
        Returns:
            {
                "response": "‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö",
                "extracted_data": {...}
            }
        """
        # ‡πÄ‡∏û‡∏¥‡πà‡∏° instruction ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö extraction ‡πÉ‡∏ô system prompt
        if extraction_schema:
            extraction_instruction = f"""
            
‡∏ô‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÅ‡∏•‡πâ‡∏ß ‡πÉ‡∏´‡πâ extract ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏° format ‡∏ô‡∏µ‡πâ:
{extraction_schema}

‡∏ï‡∏≠‡∏ö‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö:
RESPONSE: [‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤]
EXTRACTED_DATA: {{json object}}
"""
            full_system_prompt = system_prompt + extraction_instruction
        else:
            full_system_prompt = system_prompt
        
        # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å LLM
        response_text = await self.generate_response(
            system_prompt=full_system_prompt,
            user_message=user_message,
            conversation_history=conversation_history
        )
        
        # Parse response
        if "EXTRACTED_DATA:" in response_text:
            parts = response_text.split("EXTRACTED_DATA:")
            response = parts[0].replace("RESPONSE:", "").strip()
            try:
                import json
                extracted_data = json.loads(parts[1].strip())
            except:
                extracted_data = {}
        else:
            response = response_text
            extracted_data = {}
        
        return {
            "response": response,
            "extracted_data": extracted_data
        }
    
    def _get_fallback_response(self, user_message: str) -> str:
        """
        Response ‡∏™‡∏≥‡∏£‡∏≠‡∏á (‡πÉ‡∏ä‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠ API error)
        """
        return """‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞ ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏£‡∏∞‡∏ö‡∏ö‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß 
        
‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÉ‡∏ô‡∏≠‡∏µ‡∏Å‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà ‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏ó‡∏µ‡∏°‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á‡∏Ñ‡πà‡∏∞
        
üìß Email: support@lumopack.com
üìû Tel: 02-xxx-xxxx"""
    
    def set_temperature(self, temperature: float):
        """‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ temperature (0-2)"""
        if 0 <= temperature <= 2:
            self.temperature = temperature
        else:
            raise ValueError("Temperature must be between 0 and 2")
    
    def set_max_tokens(self, max_tokens: int):
        """‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ max_tokens"""
        if max_tokens > 0:
            self.max_tokens = max_tokens
        else:
            raise ValueError("max_tokens must be positive")
    
    def get_model_info(self) -> Dict:
        """‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• model ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ"""
        return {
            "model": self.model,
            "temperature": self.temperature,
            "max_tokens": self.max_tokens,
            "top_p": self.top_p
        }


# ===================================
# Global Instance (Singleton)
# ===================================
_groq_service_instance: Optional[GroqService] = None


def get_groq_service() -> GroqService:
    """
    ‡∏î‡∏∂‡∏á Groq service instance (singleton pattern)
    
    Returns:
        GroqService instance
    """
    global _groq_service_instance
    
    if _groq_service_instance is None:
        _groq_service_instance = GroqService()
    
    return _groq_service_instance


# ===================================
# Helper Functions
# ===================================
async def quick_generate(
    system_prompt: str,
    user_message: str,
    history: Optional[List[Dict]] = None
) -> str:
    """
    Quick function ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏Å LLM ‡πÅ‡∏ö‡∏ö‡∏á‡πà‡∏≤‡∏¢‡πÜ
    
    Usage:
        response = await quick_generate(
            system_prompt="You are a helpful assistant",
            user_message="Hello!"
        )
    """
    service = get_groq_service()
    return await service.generate_response(
        system_prompt=system_prompt,
        user_message=user_message,
        conversation_history=history
    )


async def test_groq_connection() -> bool:
    """
    ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Groq API
    
    Returns:
        True ‡∏ñ‡πâ‡∏≤‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏î‡πâ, False ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ
    """
    try:
        service = get_groq_service()
        response = await service.generate_response(
            system_prompt="You are a test bot",
            user_message="Say 'OK' if you can hear me"
        )
        return "OK" in response or "ok" in response.lower()
    except Exception as e:
        print(f"‚ùå Connection test failed: {e}")
        return False


# ===================================
# Example Usage
# ===================================
if __name__ == "__main__":
    import asyncio
    
    async def main():
        print("üß™ Testing Groq Service...")
        print("="*50)
        
        # Test 1: Simple generation
        print("\nüìù Test 1: Simple generation")
        response = await quick_generate(
            system_prompt="‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£",
            user_message="‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö"
        )
        print(f"Response: {response}")
        
        # Test 2: With history
        print("\nüìù Test 2: With conversation history")
        history = [
            {"role": "user", "content": "‡∏â‡∏±‡∏ô‡∏ä‡∏∑‡πà‡∏≠ John"},
            {"role": "assistant", "content": "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö‡∏Ñ‡∏∏‡∏ì John"}
        ]
        response = await quick_generate(
            system_prompt="‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£ ‡∏à‡∏≥‡∏ä‡∏∑‡πà‡∏≠‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÑ‡∏î‡πâ",
            user_message="‡∏â‡∏±‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?",
            history=history
        )
        print(f"Response: {response}")
        
        # Test 3: Connection test
        print("\nüìù Test 3: Connection test")
        is_connected = await test_groq_connection()
        print(f"Connection: {'‚úÖ OK' if is_connected else '‚ùå Failed'}")
        
        print("\n" + "="*50)
        print("‚úÖ All tests completed!")
    
    # Run tests
    asyncio.run(main())
